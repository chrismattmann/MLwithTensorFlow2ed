{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../libs/basic_units/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import python_speech_features\n",
    "from basic_units import cm, inch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal.windows import hann, hamming\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "max_iterations = 100\n",
    "segment_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mfcc = 22\n",
    "n_mels = 40\n",
    "n_fft = 16384 \n",
    "hop_length = 2205\n",
    "fmin = 0\n",
    "fmax = None\n",
    "rate = 44000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "    file_contents = tf.io.read_file(file)\n",
    "    return file, file_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = tf.io.match_filenames_once('../data/audio_dataset/*.wav')\n",
    "filename_ds = tf.data.Dataset.from_tensor_slices(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_contents_ds = filename_ds.map(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chromagram(audio_file):\n",
    "    print('filename %s ' % (audio_file))\n",
    "    y, sr = librosa.load(audio_file, sr=rate)\n",
    "    winlen=n_fft / sr\n",
    "    winstep=hop_length/sr    \n",
    "    mfcc_speech = python_speech_features.mfcc(signal=y, samplerate=sr, winlen=winlen, winstep=winstep,\n",
    "                                          numcep=n_mfcc, nfilt=n_mels, nfft=n_fft, lowfreq=fmin, highfreq=fmax,\n",
    "                                          preemph=0.0, ceplifter=0, appendEnergy=False, winfunc=hamming)   \n",
    "    return mfcc_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_vector(chroma_data):\n",
    "    num_samples, num_features = np.shape(chroma_data)\n",
    "    print(\"Num features %d num samples %d \" % (num_features, num_samples))\n",
    "    freq_vals = tf.argmax(chroma_data)\n",
    "    hist, bins = np.histogram(freq_vals, bins=range(num_features + 1))\n",
    "    return hist.astype(float) / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(audio_file):\n",
    "    chroma_data = get_chromagram(audio_file)\n",
    "    print('chroma_data', np.shape(chroma_data))\n",
    "    chroma_length = np.shape(chroma_data)[0]\n",
    "    print('chroma_length', chroma_length)\n",
    "    xs = []\n",
    "    for i in range(chroma_length // segment_size):\n",
    "        chroma_segment = chroma_data[i*segment_size:(i+1)*segment_size, :]\n",
    "        x = extract_feature_vector(chroma_segment)\n",
    "        if len(xs) == 0:\n",
    "            xs = x\n",
    "        else:\n",
    "            xs = np.vstack((xs, x))\n",
    "    return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_cluster_centroids(X, k):\n",
    "    return X[0:k, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_cluster(X, centroids):\n",
    "    expanded_vectors = tf.expand_dims(X, 0) # 1, 5, 12\n",
    "    expanded_centroids = tf.expand_dims(centroids, 1) #2, 1, 12\n",
    "    distances = tf.reduce_sum(tf.square(tf.subtract(expanded_vectors, expanded_centroids)), 2) #2, 5\n",
    "    mins = tf.argmin(distances, 0)\n",
    "    return mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recompute_centroids(X, Y):\n",
    "    sums = tf.math.unsorted_segment_sum(X, Y, k)\n",
    "    counts = tf.math.unsorted_segment_sum(tf.ones_like(X), Y, k)\n",
    "    return sums / counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename ../data/TalkingMachinesPodcast.wav \n",
      "chroma_data (626, 22)\n",
      "chroma_length 626\n",
      "Num features 22 num samples 50 \n",
      "Num features 22 num samples 50 \n",
      "Num features 22 num samples 50 \n",
      "Num features 22 num samples 50 \n",
      "Num features 22 num samples 50 \n",
      "Num features 22 num samples 50 \n",
      "Num features 22 num samples 50 \n",
      "Num features 22 num samples 50 \n",
      "Num features 22 num samples 50 \n",
      "Num features 22 num samples 50 \n",
      "Num features 22 num samples 50 \n",
      "Num features 22 num samples 50 \n",
      "(12, 22)\n",
      "iteration 50\n",
      "iteration 100\n",
      "0.0m 0.0s 0\n",
      "0.0m 5.0s 1\n",
      "0.0m 10.0s 0\n",
      "0.0m 15.0s 0\n",
      "0.0m 20.0s 1\n",
      "0.0m 25.0s 0\n",
      "0.0m 30.0s 0\n",
      "0.0m 35.0s 0\n",
      "0.0m 40.0s 0\n",
      "0.0m 45.0s 0\n",
      "0.0m 50.0s 0\n",
      "0.0m 55.0s 0\n"
     ]
    }
   ],
   "source": [
    "X = get_dataset('../data/TalkingMachinesPodcast.wav')\n",
    "print(np.shape(X))\n",
    "centroids = initial_cluster_centroids(X, k)\n",
    "i, converged = 0, False\n",
    "while not converged and i < max_iterations:\n",
    "    i += 1\n",
    "    Y = assign_cluster(X, centroids)\n",
    "    centroids = recompute_centroids(X, Y)\n",
    "    if i % 50 == 0:\n",
    "        print('iteration', i)\n",
    "\n",
    "segments = Y\n",
    "for i in range(len(segments)):\n",
    "    seconds = (i * segment_size) / float(10)\n",
    "    min, sec = divmod(seconds, 60)\n",
    "    time_str = '{}m {}s'.format(min, sec)\n",
    "    print(time_str, segments[i].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
